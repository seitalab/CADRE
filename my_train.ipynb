{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksuga/.pyenv/versions/3.7.0/envs/attention/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from my_utils import Encoder , Decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mask(y_trn, m_trn):\n",
    "  y_pos = y_trn.sum(axis=0)\n",
    "  y_neg = ((1 - y_trn) * m_trn).sum(axis=0)\n",
    "\n",
    "  y_add = np.array([[1 if (m_trn[idx,idy] == 0) and (y_pos[idy] > y_neg[idy]) else 0 for idy in range(y_trn.shape[1])] for idx in range(y_trn.shape[0])])\n",
    "\n",
    "  y_trn = y_trn + y_add\n",
    "\n",
    "  m_trn = np.ones(m_trn.shape)\n",
    "\n",
    "  return y_trn, m_trn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bin2idx(omic_bin):\n",
    "  \"\"\" Transfer a binarized matrix into a index matrix (for input of embedding layer).\n",
    "\n",
    "  omic_bin: (num_sample, num_feature), each value in {0,1}\n",
    "  omic_idx: 0 is used for padding, and therefore meaningful index starts from 1.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  num_max_omic = omic_bin.sum(axis=1).max() # max num of mutation in a single sample\n",
    "  omic_idx = np.zeros((len(omic_bin), num_max_omic), dtype=int )\n",
    "  for idx, line in enumerate(omic_bin):\n",
    "    line = [idy+1 for idy, val in enumerate(line) if val == 1]\n",
    "    omic_idx[idx][0:len(line)] = line\n",
    "\n",
    "  return omic_idx\n",
    "\n",
    "def get_ptw_ids(drug_info, tgt):\n",
    "\n",
    "  id2pw = {id:pw for id,pw in zip(drug_info.index,drug_info['Target pathway'])}\n",
    "  pws = [id2pw.get(int(c),'Unknown') for c in tgt.columns]\n",
    "  pw2id = {pw:id for id,pw in enumerate(list(set(pws)))}\n",
    "  ptw_ids = [pw2id[pw] for pw in pws]\n",
    "\n",
    "  return ptw_ids\n",
    "\n",
    "def load_dataset(input_dir=\"data/input\", drug_id=-1, shuffle_feature=False):\n",
    "    tgt = pd.read_csv(os.path.join(input_dir,'gdsc.csv'),index_col=0)\n",
    "    drug_info = pd.read_csv(os.path.join(input_dir,'drug_info_gdsc.csv'),index_col=0)\n",
    "    ptw_ids = get_ptw_ids(drug_info,tgt)\n",
    "    \n",
    "    omics_data = {'mut':None, 'cnv':None, 'exp':None, 'met':None}\n",
    "    for omic in omics_data.keys():\n",
    "        omics_data[omic] = pd.read_csv(\n",
    "            os.path.join(input_dir,omic+'_'+'gdsc.csv'), index_col=0)\n",
    "    \n",
    "    common_samples = [v.index for v in omics_data.values()]\n",
    "    common_samples = list( set(tgt.index).intersection(*common_samples))\n",
    "    \n",
    "    tgt = tgt.loc[common_samples]\n",
    "    for omic in omics_data.keys():\n",
    "        omics_data[omic] = omics_data[omic].loc[common_samples]\n",
    "\n",
    "    tmr = list(tgt.index) # barcodes/names of tumors\n",
    "    msk = tgt.notnull().astype(int).values # mask of target data: 1->data available, 0->nan\n",
    "    tgt = tgt.fillna(0).astype(int).values # fill nan element of target with 0.\n",
    "\n",
    "    num_sample = len(tmr)\n",
    "    \n",
    "    omics_data_keys = list(omics_data.keys())\n",
    "    for omic in omics_data_keys:\n",
    "        omic_val = omics_data.pop(omic)\n",
    "        omic_val = omic_val.values\n",
    "        omics_data[omic+'_bin'] = omic_val\n",
    "        omics_data[omic+'_idx'] = bin2idx(omics_data[omic+'_bin'])\n",
    "    \n",
    "    \n",
    "    omics_data['tgt'] = tgt\n",
    "    omics_data['msk'] = msk\n",
    "    omics_data['tmr'] = tmr\n",
    "    \n",
    "    return omics_data, ptw_ids\n",
    "\n",
    "def split_dataset(dataset, ratio=0.8):\n",
    "\n",
    "  num_sample = len(dataset[\"tmr\"])\n",
    "  num_train_sample = int(num_sample*ratio)\n",
    "\n",
    "  train_set = {k:dataset[k][0:num_train_sample] for k in dataset.keys()}\n",
    "  test_set = {k:dataset[k][num_train_sample:] for k in dataset.keys()}\n",
    "\n",
    "  return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, ptw_ids = load_dataset(input_dir='data/input', drug_id=-1)\n",
    "train_set, test_set = split_dataset(dataset, ratio=0.8)\n",
    "\n",
    "train_set['tgt'],train_set['msk'] = fill_mask(train_set['tgt'],train_set['msk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "omc_size =dataset['exp_bin'].shape[1]\n",
    "drg_size =dataset['tgt'].shape[1]\n",
    "emb_dim = 200\n",
    "train_size = len(train_set['tmr'])\n",
    "test_size = len(test_set['tmr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CadreDataset(data.Dataset):\n",
    "    def __init__(self,dataset_splited, phase='train'):\n",
    "        \n",
    "        self.dataset = dataset_splited\n",
    "        self.phase = phase\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.dataset['tmr'])\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        exp_idx = self.dataset['exp_idx'][index]\n",
    "        \n",
    "        labels = [self.dataset['tgt'][index], self.dataset['msk'][index]]\n",
    "\n",
    "        return exp_idx,labels\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "#dataset --> trainset testset\n",
    "#dataloader --> trainloader, testloader\n",
    "# dataloaders_dict = {'Train': -----, 'test':------}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CadreDataset(train_set,phase='train')\n",
    "test_dataset = CadreDataset(test_set,phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "train_dataloader = data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "dataloaders_dict = {'train':train_dataloader, 'test':test_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network define \n",
    "class CadreNet(nn.Module):\n",
    "    def __init__(self,ptw_ids,drg_size,omc_size,emb_dim):\n",
    "        \n",
    "        self.ptw_ids = ptw_ids\n",
    "        self.drg_size = drg_size\n",
    "        \n",
    "        self.drg_ids = np.array([list(range(self.drg_size))])\n",
    "        self.drg_ids = torch.LongTensor(self.drg_ids)\n",
    "        self.ptw_ids = torch.LongTensor([self.ptw_ids])\n",
    "        \n",
    "        \n",
    "        self.encoder = Encoder(omc_size)\n",
    "        self.decoder = Decoder(emb_dim,drg_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        hid_omc= self.encoder(inputs,ptw_ids)\n",
    "        logit_drg=self.decoder(hid_omc,drg_ids)\n",
    "        \n",
    "        return logit_drg\n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-028123beb83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCadreNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptw_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0momc_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-807577ff4b47>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ptw_ids, drg_size, omc_size, emb_dim)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CADRE/my_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, omc_size, hidden_dim, dropout_rate, embedding_dim, use_attention, attention_size, attention_head, init_gene_emb, use_cntx_attn, ptw_ids, use_hid_lyr, use_relu, repository)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_emb_ptw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptw_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "net = CadreNet(ptw_ids,drg_size,omc_size,emb_dim)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "epsilon = 1e-5\n",
    "optim = optim.SGD(params = params, lr = 0.001, momentum =0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cross_entropy(lgt_drg,tgts,msks):\n",
    "    loss = torch.sum(\n",
    "        torch.mul(criterion(lgt_drg,tgts),msks)\n",
    "        )/ (torch.sum(msks)+epsilon)\n",
    "\n",
    "def correct_num(labels,msks,preds,epsilon=1e-5):\n",
    "    \n",
    "    flat_labels = np.reshape(labels,-1)\n",
    "    flat_preds_nr = np.reshape(preds,-1)\n",
    "    flat_preds = np.reshape(np.around(preds),-1)\n",
    "    flat_msks = np.reshape(msks,-1)\n",
    "\n",
    "    flat_labels_msk = np.array([flat_labels[idx] for idx, val in enumerate(flat_msks) if val == 1])\n",
    "    flat_preds_msk = np.array([flat_preds[idx] for idx, val in enumerate(flat_msks) if val == 1])\n",
    "    flat_preds_nr_msk = np.array([flat_preds_nr[idx] for idx, val in enumerate(flat_msks) if val == 1])\n",
    "\n",
    "    accuracy = np.sum(flat_labels_msk == flat_preds_msk)\n",
    "    \n",
    "    return correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "        \n",
    "        for phase in ['train','test']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.test()\n",
    "                \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "                \n",
    "            for inputs,labels in tqdm(dataloaders_dict[phase]):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _,preds = torch.max(outputs,1)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss_ent = loss_cross_entropy(outputs,tgts,msks)\n",
    "                    loss = loss_ent\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "                epoch_corrects += correct_num(labels,msks,preds,epsilon=1e-5)\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double()/ len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:,4f} Acc: {:.4f}'.format(phase,epoch_loss,epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = num_epochs\n",
    "train_model(CadreNet, dataloaders_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def evaluate():\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
